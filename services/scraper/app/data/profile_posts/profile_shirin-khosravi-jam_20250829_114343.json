{
  "identifier": "shirin-khosravi-jam",
  "type": "profile",
  "scraped_at": "2025-08-29T17:13:43.974515+05:30",
  "total_posts": 6,
  "posts": [
    {
      "id": "If I had to start as an AI Engineer in 2025, this _458",
      "text": "If I had to start as an AI Engineer in 2025, this is the exact plan. 99+ hours of research later! (with timelines & resources) Save it now! 0) Set your base (2–3 weeks): Python + DS&A ⏎ https://lnkd.in/dmmfnf-z (Udemy) ⏎ https://lnkd.in/gwPGw-53 (NeetCode 150) Math + Classic ML ⏎ https://lnkd.in/gn9WR-aE (3Blue1Brown) ⏎ https://lnkd.in/gAC6iSWN (Andrew Ng ML) ⏎ https://lnkd.in/gMMd6Ezu (Hands-On ML) 1) Think in systems, not just models (2–3 weeks) Deep Learning fast-track ⏎ https://lnkd.in/gs5Wqzj5 (MIT 6.S191) ⏎ https://lnkd.in/gYzeJMTc (NN Zero-to-Hero) PyTorch & theory ⏎ https://lnkd.in/gN_cUA7h (PyTorch Blitz) ⏎ https://lnkd.in/g4xgvu_q (Understanding Deep Learning) MLOps & scaling ⏎ https://lnkd.in/g5XGChfH (Full-Stack DL) ⏎ https://lnkd.in/gP3UDqwn (Stanford MLSys) ⏎ https://lnkd.in/gp-WeZte (AI Engineering Book) 2) Ship RAG the right way (2–3 weeks) Videos ⏎ https://lnkd.in/gYVF6CfT (What is RAG) ⏎ https://lnkd.in/g-953k9V (How to use RAG) ⏎ https://lnkd.in/gFXF6DZV (CMU Advanced NLP – RAG) Papers ⏎ https://lnkd.in/gW8ee2q6 (RAG) Repos/Courses ⏎ https://lnkd.in/g2ZHwZ3w (Advanced RAG) ⏎ https://lnkd.in/g4ppP4-H (Awesome RAG) ⏎ https://lnkd.in/gKCUaN7G (DL.ai RAG) 3) Learn Agents like an engineer (2–3 weeks) Read first ⏎ https://lnkd.in/gFvCfbSN (Google Agent WP) ⏎ https://lnkd.in/gRWKANS4 (Anthropic guide) ⏎ https://lnkd.in/guRfXsFK (OpenAI guide) Watch most popular series: ⏎ https://lnkd.in/gN8sv7Q5 ⏎ https://lnkd.in/gJt-SQj2 ⏎ https://lnkd.in/gk4GKdxa ⏎ https://lnkd.in/ghBiVjdF ⏎ https://lnkd.in/g_m78sid ⏎ https://lnkd.in/gAzBzr3W ⏎ https://lnkd.in/g9GR9b9F ⏎ https://lnkd.in/gnxRq9n9 Courses ⏎ https://lnkd.in/gmTftTXV (HF Agents) ⏎ https://lnkd.in/geffcwdq (Anthropic MCP) ⏎ https://lnkd.in/g5ytvtH7 (Berkeley Agents) 4) Read what top teams ship (15 min/day) ⏎ https://lnkd.in/g7-kjM9K (Google) ⏎ https://ai.meta.com/blog/ (Meta) ⏎ https://lnkd.in/gWS44qbK (Netflix) ⏎ https://lnkd.in/gZn-4NWn (Amazon) ⏎ https://lnkd.in/gmvQVn3v (Microsoft) ⏎ https://lnkd.in/gyuMHRrE (OpenAI) ⏎ https://lnkd.in/gjBHNh2g (Uber) ⏎ https://lnkd.in/gX-rAhwS (Databricks) 5) Interviews & portfolio ⏎ https://lnkd.in/gwPGw-53 (NeetCode 150) ⏎ https://lnkd.in/gzGhDGgq (Stanford CS329S) ⏎ https://lnkd.in/gmAg4nBb (System Design Primer) ⏎ https://lnkd.in/gx5YF6yJ (DL Interviews) ⏎ https://lnkd.in/gzZzMv4k (ML Q&A) ⏎ https://lnkd.in/gAKDS4_e (Tech Interview HB) 6) Projects that make recruiters stop ⏎ Join \"The Mother of AI\" project here: https://lnkd.in/dub8tgV9 Weekly cadence ⏎ Mon–Thu: 60-90m study → 60-90m build ⏎ Fri: “what I shipped” post ⏎ Sat: refactor + tests/evals ⏎ Sun: 3 blogs + plan Make use of ChatGPT and Coding Assistant to learn and build projects! I hope I didn't miss anything! What do you think of this roadmap? ♻️ Repost if you like it 💚 ➕ 𝘑𝘰𝘪𝘯 19000+ 𝘳𝘦𝘢𝘭-𝘸𝘰𝘳𝘭𝘥 𝘔𝘓/𝘈𝘐 𝘣𝘶𝘪𝘭𝘥𝘦𝘳𝘴: https://lnkd.in/ds_SzEUH",
      "likes": 458,
      "comments": 74,
      "reposts": 72,
      "engagement": 604,
      "scraped_at": "2025-08-29T17:13:39.416144+05:30",
      "source": "profile",
      "profile_url": "https://linkedin.com/in/shirin-khosravi-jam"
    },
    {
      "id": "After shipping AI Agents & RAG to production… thes_322",
      "text": "After shipping AI Agents & RAG to production… these are the only books you need to cover NLP 👇 NLP (foundations → LLMs): the short stack 1. 𝗛𝗮𝗻𝗱𝘀-𝗢𝗻 𝗠𝗮𝗰𝗵𝗶𝗻𝗲 𝗟𝗲𝗮𝗿𝗻𝗶𝗻𝗴 𝘄𝗶𝘁𝗵 𝗦𝗰𝗶𝗸𝗶𝘁-𝗟𝗲𝗮𝗿𝗻, 𝗞𝗲𝗿𝗮𝘀 & 𝗧𝗲𝗻𝘀𝗼𝗿𝗙𝗹𝗼𝘄 - Aurélien → Core ML that powers NLP: regression, trees, SVMs, NNs. → End-to-end projects; concepts transfer to PyTorch easily. 2. 𝗣𝘆𝘁𝗵𝗼𝗻 𝗡𝗮𝘁𝘂𝗿𝗮𝗹 𝗟𝗮𝗻𝗴𝘂𝗮𝗴𝗲 𝗣𝗿𝗼𝗰𝗲𝘀𝘀𝗶𝗻𝗴 𝗖𝗼𝗼𝗸𝗯𝗼𝗼𝗸 - Zhenya & Saurabh → Tokenization, n-grams, TF-IDF/BM25, NER, classic embeddings. → Practical recipes with spaCy + Hugging Face. 3. 𝗡𝗮𝘁𝘂𝗿𝗮𝗹 𝗟𝗮𝗻𝗴𝘂𝗮𝗴𝗲 𝗣𝗿𝗼𝗰𝗲𝘀𝘀𝗶𝗻𝗴 𝘄𝗶𝘁𝗵 𝗧𝗿𝗮𝗻𝘀𝗳𝗼𝗿𝗺𝗲𝗿𝘀 - Lewis, Leandro, Thomas → BERT → sentence-transformers; real HF workflows (CLS, QA, STS). → Clear view of transformer internals you’ll actually use. 4. 𝗛𝗮𝗻𝗱𝘀-𝗢𝗻 𝗟𝗮𝗿𝗴𝗲 𝗟𝗮𝗻𝗴𝘂𝗮𝗴𝗲 𝗠𝗼𝗱𝗲𝗹𝘀 - Jay & Maarten → Build a transformer from scratch; prompting, RAG, evals. → Function calling + agent patterns that survive prod. ➕ Bonus: Build a Large Language Model (From Scratch) - Sebastian → Training/inference nuts-and-bolts; great for serious builders. Make it stick: → After each chapter, ship one tiny artifact: BM25 search → NER API → BERT finetune → RAG endpoint. → Track 4 signals: accuracy, p95 latency, cost/request, failure modes. → Rinse, iterate, demo. That’s it. Fewer books. More building. Better NLP. DM me if you want links to them 😇 PS: Credits to Shantanu for the roadmap! ♻️ Save/share if you’re serious about AI Engineering in 2025. ➕ Follow for production AI/RAG/Agents + career playbooks.",
      "likes": 322,
      "comments": 73,
      "reposts": 36,
      "engagement": 431,
      "scraped_at": "2025-08-29T17:13:39.844425+05:30",
      "source": "profile",
      "profile_url": "https://linkedin.com/in/shirin-khosravi-jam"
    },
    {
      "id": "AI Agents are not LangChain. AI Agents are not MCP_437",
      "text": "AI Agents are not LangChain. AI Agents are not MCP. AI Agents are not “just tools wired together.” You’re not gluing APIs - you’re shipping outcomes. 1️⃣ 𝗪𝗵𝗮𝘁 𝗴𝗿𝗲𝗮𝘁 𝗯𝘂𝗶𝗹𝗱𝗲𝗿𝘀 𝗱𝗼 ✅ Start from a real task + SLOs (success %, p95, $/req) ✅ Define tools + guardrails (JSON schemas, least-privilege, sandbox, quotas) ✅ Make it observable (traces, step logs, replays, per-step budgets) ✅ Add determinism (cache, simple rules, idempotent tools, human-in-loop) ✅ Evaluate for real (task success, intervention rate, regression gates) ✅ Tune for prod (routing, batching, timeouts/retries, rate limits, cost caps) ✅ Roll out CC/CD (shadow → suggest → review → auto, with fallbacks) 2️⃣ 𝗣𝗿𝗼𝗱 𝗰𝗵𝗲𝗰𝗸𝗹𝗶𝘀𝘁 — Feature flag + shadow mode — Per-step limits: timeout, budget, retry — Tool contracts: JSON schema + validate + PII removal — Observability: traces/metrics/logs + alerts on cost/latency/quality — Escape hatches: cache/default, human override, rollback 3️⃣ 𝗛𝗼𝘄 𝘀𝘂𝗰𝗰𝗲𝘀𝘀 𝗶𝘀 𝗺𝗲𝗮𝘀𝘂𝗿𝗲𝗱 — Completes tasks end-to-end, solo — Recovers fast when it breaks — Small blast radius, tight permissions — Real KPI lift (time ↓, revenue ↑) Bottom line: not a framework choice. Agents are systems that deliver value - safely, reliably, repeatedly. Do you agree with the kart vs car analogy? ♻️ Repost to help other builders 💚",
      "likes": 437,
      "comments": 101,
      "reposts": 29,
      "engagement": 567,
      "scraped_at": "2025-08-29T17:13:40.701389+05:30",
      "source": "profile",
      "profile_url": "https://linkedin.com/in/shirin-khosravi-jam"
    },
    {
      "id": "Literally no one tells you this 👇 99% haven’t ship_303",
      "text": "Literally no one tells you this 👇 99% haven’t shipped RAG to prod. Here’s how it actually gets built. (I’ve built RAG + AI Agents in production.) It’s not just plugging in OpenAI + a vector DB. Save this list 👇 1️⃣ 𝗧𝗵𝗲 𝗕𝗮𝘀𝗶𝗰𝘀 → What’s the user problem? → What’s the feature we’re enabling? → Do we really need RAG? Rules or IR might work better. 2️⃣ 𝗗𝗮𝘁𝗮 𝗔𝘂𝗱𝗶𝘁 → Do we have the right documents? → Are they structured or unstructured? Clean? Complete? → Do we need extraction like HTML parsing or OCR? 3️⃣ 𝗗𝗮𝘁𝗮 𝗣𝗿𝗲𝗽𝗿𝗼𝗰𝗲𝘀𝘀𝗶𝗻𝗴 → Chunking strategy → fixed, semantic, overlap? → Extract metadata, HTML clean-up, language detection → NER or Classification to filter/query data → Choose between vector retrieval / hybrid / keyword / rule-based 4️⃣ 𝗥𝗮𝗽𝗶𝗱 𝗣𝗿𝗼𝘁𝗼𝘁𝘆𝗽𝗶𝗻𝗴 𝗶𝗻 𝗡𝗼𝘁𝗲𝗯𝗼𝗼𝗸 → Try embeddings + vector search (OpenAI, BGE, E5) → Store locally (FAISS) or use pgvector for quick validation → Evaluate retrieval manually with query–chunk pairs → Start small → get 10–20 examples right 5️⃣ 𝗕𝘂𝗶𝗹𝗱 𝗥𝗲𝘁𝗿𝗶𝗲𝘃𝗮𝗹 𝗟𝗼𝗴𝗶𝗰 → Try different similarity techniques (cosine, HNSW, hybrid) → Add business logic to boost or suppress results → Consider cost vs latency vs quality → Use bi-encoders or cross-encoders (re-rankers) if needed → Using custom models? Now you need MLOps too! 6️⃣ 𝗟𝗟𝗠 𝗥𝗲𝘀𝗽𝗼𝗻𝘀𝗲 𝗗𝗲𝘀𝗶𝗴𝗻 → Pick a model (OpenAI, Claude, Mistral) → Design prompts, add guardrails → Handle hallucinations, cost, and context limits 7️⃣ 𝗘𝘃𝗮𝗹𝘂𝗮𝘁𝗶𝗼𝗻 (𝗦𝘂𝗽𝗲𝗿 𝗜𝗺𝗽𝗼𝗿𝘁𝗮𝗻𝘁!) → Build Golden dataset → Use RAGAS, LLM-judge, human evals → Metrics: Recall@k, MRR, helpfulness 8️⃣ 𝗜𝘁𝗲𝗿𝗮𝘁𝗶𝗼𝗻 & 𝗘𝘅𝗽𝗲𝗿𝗶𝗺𝗲𝗻𝘁𝗮𝘁𝗶𝗼𝗻 → Try OCR tweaks → breaks chunking? fix again → Change embedding model → update backfill pipeline → Add filters, rerankers, fallback mechanisms 9️⃣ 𝗙𝗿𝗼𝗺 𝗡𝗼𝘁𝗲𝗯𝗼𝗼𝗸 𝘁𝗼 𝗜𝗻𝗳𝗿𝗮 → Build the data pipeline if needed → Set up Vector DB / SQL DB / hybrid system → Dockerize, CI/CD, push to cloud (ECR, Lambda, ECS, Vertex, etc.) → Add monitoring (token usage, latency, failure rate) → Setup dashboards (Grafana, Prometheus, DataDog, etc.) 🔟 𝗥𝗼𝗹𝗹𝗼𝘂𝘁 & 𝗙𝗲𝗲𝗱𝗯𝗮𝗰𝗸 𝗟𝗼𝗼𝗽 → Add logs → retrieval candidates + selected context → Enable user feedback logging → AB test against product KPIs (CTR, time-on-task, bounce rate) → Use structured feedback to retrain ranking models 🔁 𝗖𝗼𝗻𝘁𝗶𝗻𝘂𝗼𝘂𝘀 𝗜𝗺𝗽𝗿𝗼𝘃𝗲𝗺𝗲𝗻𝘁 → Fine-tune embeddings → Use cross-encoders → Add fallback strategies → New OCR? New docs? Repeat pre-processing 😅 🧠 𝗕𝗼𝗻𝘂𝘀 𝗥𝗲𝗮𝗹𝗶𝘁𝗶𝗲𝘀 → Requirements will change → Legal/GDPR will knock → Stakeholders want analytics → You’ll need to explain retrieval logic to non-tech teams → Didn’t even cover LLMOps or Agentic RAG yet… The process never ends and that’s the point. It’s system design. What would you add (or cut)? ♻️ Repost to save someone months of dead-ends 💚",
      "likes": 303,
      "comments": 60,
      "reposts": 36,
      "engagement": 399,
      "scraped_at": "2025-08-29T17:13:41.587500+05:30",
      "source": "profile",
      "profile_url": "https://linkedin.com/in/shirin-khosravi-jam"
    },
    {
      "id": "I did a bachelor’s & master’s… but the truth? Thes_401",
      "text": "I did a bachelor’s & master’s… but the truth? These 10 YouTube channels taught me the AI skills than any degree! I didn’t come from CS. I learned it all myself. If that’s you, start here 👇 I know how valuable these resources could be for someone on the same journey! 🔹 Foundations & Beyond: 1️⃣ StatQuest with Joshua Starmer PhD → Makes scary topics like statistics & ML feel joyful and simple → Start here if math makes you nervous 2️⃣ 3Blue1Brown → The most intuitive explanations of linear algebra, calculus, and neural nets → Especially powerful for building visual understanding of complex math 3️⃣ sentdex → Massive Python playlist library (ML, NLP, deep learning, and more) → Great if you prefer code-driven, project-based tutorials 4️⃣ Stanford Online → Classic university lectures made public → The playlist keeps getting updated with more and more latest content around AI. 🔹 LLMs & Beyond: 5️⃣ Andrej Karpathy → Deep dives on how LLMs and neural networks actually work → His “zero-to-hero” coding series is gold for understanding transformers 6️⃣ Sebastian Raschka, PhD → Practical, well-explained content on ML, deep learning, and LLMs → Often goes beyond theory into real-world training/debugging insights 🔹 Hands-on Content 7️⃣ Krish Naik → Consistent tutorials on applied ML, deep learning, and real-world deployments → Perfect for job-seekers and early-career practitioners 8️⃣ Patrick Löber (aka Python Engineer) → Clean, concise Python + ML tutorials → Fast way to build portfolio-ready projects from scratch 9️⃣ freeCodeCamp org → Full 10-hour+ courses on ML, Python, data science - for free → Great for anyone who wants deep structure without cost 🔟 Dave Ebbelaar → Focus on MLOps, real-world data workflows, and AI pipelines → Super relevant if you want to learn how production systems actually work Any other youtube channel you would recommend? Comment below and let's help the community 👇 ♻️ Save + Repost to help other 💚",
      "likes": 401,
      "comments": 59,
      "reposts": 49,
      "engagement": 509,
      "scraped_at": "2025-08-29T17:13:42.304469+05:30",
      "source": "profile",
      "profile_url": "https://linkedin.com/in/shirin-khosravi-jam"
    },
    {
      "id": "Stop hoarding 17 AI-agent courses. Build with 5, s_141",
      "text": "Stop hoarding 17 AI-agent courses. Build with 5, ship 1. If you plan to build & sell agents, start here 👇 🔹 𝗪𝗵𝘆 𝗹𝗲𝘀𝘀 𝗶𝘀 𝗺𝗼𝗿𝗲 1️⃣ Depth beats playlists → you don’t need 17 intros. 2️⃣ Systems > snippets → shipping teaches routing, evals, and cost. 3️⃣ Numbers win interviews → p95, cost/request, success rate. 🔹 𝗠𝘆 𝟱-𝗹𝗶𝗻𝗸 𝘀𝘁𝗮𝗿𝘁𝗲𝗿 𝗽𝗮𝗰𝗸 (𝗻𝗼𝘁 𝟭𝟳) 1️⃣ LangGraph (agents/orchestration) → planning, state, tools, retries ↳ https://lnkd.in/dABmZEyB 2️⃣ Prompt engineering (official) → roles, structure, function specs ↳ https://lnkd.in/dQw-x5Yb 3️⃣ RAG fundamentals (hybrid search) → BM25 × vectors × fusion ↳ https://lnkd.in/d4Sg_JnE 4️⃣ RAG evaluation (Ragas) → faithfulness, answer quality, end-to-end evals ↳ https://lnkd.in/duE-eNrV 5️⃣ LLM observability (Langfuse) → traces, costs, latency, feedback loops ↳ https://langfuse.com/docs 🔹 𝗦𝗵𝗶𝗽 𝗶𝘁 (𝗔𝗣𝗜𝘀 & 𝗶𝗻𝗳𝗿𝗮) 6️⃣ FastAPI (async APIs) → type-safe routes, DI, auto-docs ↳ https://lnkd.in/dMmTz_ga 7️⃣ Docker (dev→prod) → containerize & deploy fast ↳ https://lnkd.in/dkqvfU7K (people often underestimate the power of the original documentations!) 🔹 𝗦𝘁𝘂𝗱𝘆 𝗹𝗼𝗼𝗽 (𝟮 𝘄𝗲𝗲𝗸𝘀, 𝗿𝗲𝗽𝗲𝗮𝘁) Day 1–3 → learn one topic → Day 4–7 ship a feature → Day 8–10 add tracing/evals → Day 11–14 measure & refactor. ✅ Track: p95, cost/request, success %, answer quality. 🔹 𝗣𝗼𝗿𝘁𝗳𝗼𝗹𝗶𝗼 𝗰𝗵𝗲𝗰𝗸𝗹𝗶𝘀𝘁 → README with a 30-sec arch sketch → Before/after numbers (latency, cost, quality) → Screenshots of traces/evals → One postmortem: what broke, how you fixed it Thats it! Dont overcomplicate! What do you think? Comment below 👇 ♻️ If this resonates, Save + Repost to help other 💚",
      "likes": 141,
      "comments": 47,
      "reposts": 15,
      "engagement": 203,
      "scraped_at": "2025-08-29T17:13:42.656633+05:30",
      "source": "profile",
      "profile_url": "https://linkedin.com/in/shirin-khosravi-jam"
    }
  ]
}